{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os, sys\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['HADOOP_HOME'] = \"C:\\\\apps\\hadoop\"\n",
    "os.environ['SPARK_HOME'] = \"C:\\\\apps\\spark-3.5.0-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Status|\n",
      "+------+\n",
      "|    OK|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql('''select \"OK\" as Status''')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 77\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|                name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|           100% Bran|  N|   C|      70|      4|  1|   130| 10.0|  5.0|     6|   280|      25|    3|   1.0|0.33|68.402973|\n",
      "|   100% Natural Bran|  Q|   C|     120|      3|  5|    15|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|\n",
      "|            All-Bran|  K|   C|      70|      4|  1|   260|  9.0|  7.0|     5|   320|      25|    3|   1.0|0.33|59.425505|\n",
      "|All-Bran with Ext...|  K|   C|      50|      4|  0|   140| 14.0|  8.0|     0|   330|      25|    3|   1.0| 0.5|93.704912|\n",
      "|      Almond Delight|  R|   C|     110|      2|  2|   200|  1.0| 14.0|     8|    -1|      25|    3|   1.0|0.75|34.384843|\n",
      "|Apple Cinnamon Ch...|  G|   C|     110|      2|  2|   180|  1.5| 10.5|    10|    70|      25|    1|   1.0|0.75|29.509541|\n",
      "|         Apple Jacks|  K|   C|     110|      2|  0|   125|  1.0| 11.0|    14|    30|      25|    2|   1.0| 1.0|33.174094|\n",
      "|             Basic 4|  G|   C|     130|      3|  2|   210|  2.0| 18.0|     8|   100|      25|    3|  1.33|0.75|37.038562|\n",
      "|           Bran Chex|  R|   C|      90|      2|  1|   200|  4.0| 15.0|     6|   125|      25|    1|   1.0|0.67|49.120253|\n",
      "|         Bran Flakes|  P|   C|      90|      3|  0|   210|  5.0| 13.0|     5|   190|      25|    3|   1.0|0.67|53.313813|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('./cereal.csv', sep=',', inferSchema=True, header=True)\n",
    "\n",
    "print(f'Lines: {df.count()}')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- mfr: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- calories: integer (nullable = true)\n",
      " |-- protein: integer (nullable = true)\n",
      " |-- fat: integer (nullable = true)\n",
      " |-- sodium: integer (nullable = true)\n",
      " |-- fiber: double (nullable = true)\n",
      " |-- carbo: double (nullable = true)\n",
      " |-- sugars: integer (nullable = true)\n",
      " |-- potass: integer (nullable = true)\n",
      " |-- vitamins: integer (nullable = true)\n",
      " |-- shelf: integer (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- cups: double (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate date with Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('cereal_sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|                name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|           100% Bran|  N|   C|      70|      4|  1|   130| 10.0|  5.0|     6|   280|      25|    3|   1.0|0.33|68.402973|\n",
      "|   100% Natural Bran|  Q|   C|     120|      3|  5|    15|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|\n",
      "|            All-Bran|  K|   C|      70|      4|  1|   260|  9.0|  7.0|     5|   320|      25|    3|   1.0|0.33|59.425505|\n",
      "|All-Bran with Ext...|  K|   C|      50|      4|  0|   140| 14.0|  8.0|     0|   330|      25|    3|   1.0| 0.5|93.704912|\n",
      "|      Almond Delight|  R|   C|     110|      2|  2|   200|  1.0| 14.0|     8|    -1|      25|    3|   1.0|0.75|34.384843|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cereal = spark.sql('''SELECT * FROM cereal_sql''')\n",
    "df_cereal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 74\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|                name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|           100% Bran|  N|   C|      70|      4|  1|   130| 10.0|  5.0|     6|   280|      25|    3|   1.0|0.33|68.402973|\n",
      "|   100% Natural Bran|  Q|   C|     120|      3|  5|    15|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|\n",
      "|            All-Bran|  K|   C|      70|      4|  1|   260|  9.0|  7.0|     5|   320|      25|    3|   1.0|0.33|59.425505|\n",
      "|All-Bran with Ext...|  K|   C|      50|      4|  0|   140| 14.0|  8.0|     0|   330|      25|    3|   1.0| 0.5|93.704912|\n",
      "|      Almond Delight|  R|   C|     110|      2|  2|   200|  1.0| 14.0|     8|    -1|      25|    3|   1.0|0.75|34.384843|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter = spark.sql('''SELECT * FROM cereal_sql WHERE type = \"C\"''')\n",
    "print(f'Lines: {filter.count()}')\n",
    "filter.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting lines as new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|total|\n",
      "+-----+\n",
      "|   23|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter = spark.sql('''SELECT COUNT(*) AS total FROM cereal_sql WHERE mfr = \"K\"''')\n",
    "filter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variações do comando Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+\n",
      "|                name|type|mfr|\n",
      "+--------------------+----+---+\n",
      "|           100% Bran|   C|  N|\n",
      "|   100% Natural Bran|   C|  Q|\n",
      "|            All-Bran|   C|  K|\n",
      "|All-Bran with Ext...|   C|  K|\n",
      "|      Almond Delight|   C|  R|\n",
      "+--------------------+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Colunas específicas\n",
    "cereal = spark.sql('''SELECT name,type,mfr FROM cereal_sql ''')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 77\n",
      "+----+---+\n",
      "|type|mfr|\n",
      "+----+---+\n",
      "|   C|  N|\n",
      "|   C|  Q|\n",
      "|   C|  K|\n",
      "|   C|  K|\n",
      "|   C|  R|\n",
      "+----+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Lines: 9\n",
      "+----+---+\n",
      "|type|mfr|\n",
      "+----+---+\n",
      "|   C|  P|\n",
      "|   C|  Q|\n",
      "|   C|  N|\n",
      "|   H|  Q|\n",
      "|   C|  R|\n",
      "+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valores distintos\n",
    "cereal = spark.sql('''SELECT type,mfr FROM cereal_sql ''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)\n",
    "\n",
    "cereal = spark.sql('''SELECT DISTINCT type,mfr FROM cereal_sql ''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comando Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 6\n",
      "+----+---+\n",
      "|type|mfr|\n",
      "+----+---+\n",
      "|   C|  P|\n",
      "|   C|  Q|\n",
      "|   C|  N|\n",
      "|   C|  R|\n",
      "|   C|  G|\n",
      "+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql('''SELECT DISTINCT type,mfr FROM cereal_sql WHERE type = \"C\"''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 19\n",
      "+------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|              name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|       Apple Jacks|  K|   C|     110|      2|  0|   125|  1.0| 11.0|    14|    30|      25|    2|   1.0| 1.0|33.174094|\n",
      "|       Corn Flakes|  K|   C|     100|      2|  0|   290|  1.0| 21.0|     2|    35|      25|    1|   1.0| 1.0|45.863324|\n",
      "|         Corn Pops|  K|   C|     110|      1|  0|    90|  1.0| 13.0|    12|    20|      25|    2|   1.0| 1.0|35.782791|\n",
      "|Cracklin' Oat Bran|  K|   C|     110|      3|  3|   140|  4.0| 10.0|     7|   160|      25|    3|   1.0| 0.5|40.448772|\n",
      "|           Crispix|  K|   C|     110|      2|  0|   220|  1.0| 21.0|     3|    30|      25|    3|   1.0| 1.0|46.895644|\n",
      "+------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dupla condição\n",
    "cereal = spark.sql('''SELECT * FROM cereal_sql WHERE mfr = \"K\" AND calories >= 100''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "|mfr|type|count|\n",
      "+---+----+-----+\n",
      "|  A|   H|    1|\n",
      "|  P|   C|    9|\n",
      "|  K|   C|   23|\n",
      "|  G|   C|   22|\n",
      "|  Q|   C|    7|\n",
      "|  R|   C|    8|\n",
      "|  Q|   H|    1|\n",
      "|  N|   H|    1|\n",
      "|  N|   C|    5|\n",
      "+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento simples\n",
    "cereal = spark.sql(''' SELECT mfr,type,COUNT(*) AS count FROM cereal_sql GROUP BY mfr,type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+--------------+\n",
      "|mfr|type|count|total_calories|\n",
      "+---+----+-----+--------------+\n",
      "|  A|   H|    1|           100|\n",
      "|  P|   C|    9|           980|\n",
      "|  K|   C|   23|          2500|\n",
      "|  G|   C|   22|          2450|\n",
      "|  Q|   C|    7|           660|\n",
      "|  R|   C|    8|           920|\n",
      "|  Q|   H|    1|           100|\n",
      "|  N|   H|    1|           100|\n",
      "|  N|   C|    5|           420|\n",
      "+---+----+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento com mais de uma agregação\n",
    "cereal = spark.sql(''' SELECT mfr,type,COUNT(*) AS count, SUM(calories) as total_calories FROM cereal_sql GROUP BY mfr,type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+--------------+\n",
      "|mfr|type|count|total_calories|\n",
      "+---+----+-----+--------------+\n",
      "|  A|   H|    1|           100|\n",
      "|  P|   C|    9|           980|\n",
      "|  K|   C|   23|          2500|\n",
      "|  G|   C|   22|          2450|\n",
      "|  Q|   C|    7|           660|\n",
      "|  R|   C|    8|           920|\n",
      "|  Q|   H|    1|           100|\n",
      "|  N|   H|    1|           100|\n",
      "|  N|   C|    5|           420|\n",
      "+---+----+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento com mais de uma agregação\n",
    "cereal = spark.sql(''' SELECT \\\n",
    "                           mfr, type, COUNT(*) AS count, SUM(calories) as total_calories \\\n",
    "                       FROM cereal_sql\\\n",
    "                       GROUP BY mfr,type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE WHEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|type|\n",
      "+----+\n",
      "|   C|\n",
      "|   H|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql(''' SELECT DISTINCT\\\n",
    "                           type \\\n",
    "                       FROM cereal_sql''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+-----+\n",
      "|mfr|type|category|count|\n",
      "+---+----+--------+-----+\n",
      "|  A|   H|  tipo H|    1|\n",
      "|  P|   C|  tipo C|    9|\n",
      "|  K|   C|  tipo C|   23|\n",
      "|  G|   C|  tipo C|   22|\n",
      "|  Q|   C|  tipo C|    7|\n",
      "|  R|   C|  tipo C|    8|\n",
      "|  Q|   H|  tipo H|    1|\n",
      "|  N|   H|  tipo H|    1|\n",
      "|  N|   C|  tipo C|    5|\n",
      "+---+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql(''' SELECT\\\n",
    "                           mfr, type, (case when type = \"C\" then \"tipo C\" else \"tipo H\" end) as category, count(*) as count \\\n",
    "                       FROM cereal_sql\\\n",
    "                       GROUP BY mfr, type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+-----+\n",
      "|mfr|type|category|count|\n",
      "+---+----+--------+-----+\n",
      "|  A|   H|    NULL|    1|\n",
      "|  P|   C|  tipo C|    9|\n",
      "|  K|   C|  tipo C|   23|\n",
      "|  G|   C|  tipo C|   22|\n",
      "|  Q|   C|  tipo C|    7|\n",
      "|  R|   C|  tipo C|    8|\n",
      "|  Q|   H|    NULL|    1|\n",
      "|  N|   H|    NULL|    1|\n",
      "|  N|   C|  tipo C|    5|\n",
      "+---+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Células comentadas em SQL\n",
    "cereal = spark.sql(''' SELECT\n",
    "                           mfr, type,\n",
    "                           (case\n",
    "                                when type = \"C\" then \"tipo C\"\n",
    "                                --when type = \"H\" then \"tipo B\"\n",
    "                                --else \"tipo H\"\n",
    "                           end) as category,\n",
    "                           count(*) as count \n",
    "                       FROM cereal_sql\n",
    "                       GROUP BY mfr, type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultas avançadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------------+------------+------------+------------------+-----+\n",
      "|mfr|type|sum_calories|min_calories|max_calories|      avg_calories|count|\n",
      "+---+----+------------+------------+------------+------------------+-----+\n",
      "|  K|   C|        2500|          50|         160|108.69565217391305|   23|\n",
      "|  G|   C|        2450|         100|         140|111.36363636363636|   22|\n",
      "|  P|   C|         980|          90|         120|108.88888888888889|    9|\n",
      "|  R|   C|         920|          90|         150|             115.0|    8|\n",
      "|  Q|   C|         660|          50|         120| 94.28571428571429|    7|\n",
      "|  N|   C|         420|          70|          90|              84.0|    5|\n",
      "|  A|   H|         100|         100|         100|             100.0|    1|\n",
      "|  Q|   H|         100|         100|         100|             100.0|    1|\n",
      "|  N|   H|         100|         100|         100|             100.0|    1|\n",
      "+---+----+------------+------------+------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql('''  SELECT mfr, type,\n",
    "                                sum(calories) as sum_calories,\n",
    "                                min(calories) as min_calories,\n",
    "                                max(calories) as max_calories,\n",
    "                                avg(calories) as avg_calories,\n",
    "                                count(name) as count\n",
    "                        FROM cereal_sql\n",
    "                        GROUP BY mfr,type\n",
    "                        ORDER BY count DESC\n",
    "\n",
    "''')\n",
    "\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------------+------------+------------+------------------+---------+---------+---------+------------------+------------+------------+------------+------------------+-----+\n",
      "|mfr|type|sum_calories|min_calories|max_calories|      avg_calories|sum_carbo|min_carbo|max_carbo|         avg_carbo|sum_vitamins|min_vitamins|max_vitamins|      avg_vitamins|count|\n",
      "+---+----+------------+------------+------------+------------------+---------+---------+---------+------------------+------------+------------+------------+------------------+-----+\n",
      "|  K|   C|        2500|          50|         160|108.69565217391305|    348.0|      7.0|     22.0|15.130434782608695|         800|          25|         100| 34.78260869565217|   23|\n",
      "|  G|   C|        2450|         100|         140|111.36363636363636|    324.0|     10.5|     21.0|14.727272727272727|         775|          25|         100| 35.22727272727273|   22|\n",
      "|  P|   C|         980|          90|         120|108.88888888888889|    119.0|     11.0|     17.0|13.222222222222221|         225|          25|          25|              25.0|    9|\n",
      "|  R|   C|         920|          90|         150|             115.0|    141.0|     14.0|     23.0|            17.625|         200|          25|          25|              25.0|    8|\n",
      "|  Q|   C|         660|          50|         120| 94.28571428571429|     81.0|      8.0|     14.0|11.571428571428571|         100|           0|          25|14.285714285714286|    7|\n",
      "|  N|   C|         420|          70|          90|              84.0|     75.0|      5.0|     20.0|              15.0|          50|           0|          25|              10.0|    5|\n",
      "|  A|   H|         100|         100|         100|             100.0|     16.0|     16.0|     16.0|              16.0|          25|          25|          25|              25.0|    1|\n",
      "|  Q|   H|         100|         100|         100|             100.0|     -1.0|     -1.0|     -1.0|              -1.0|           0|           0|           0|               0.0|    1|\n",
      "|  N|   H|         100|         100|         100|             100.0|     21.0|     21.0|     21.0|              21.0|           0|           0|           0|               0.0|    1|\n",
      "+---+----+------------+------------+------------+------------------+---------+---------+---------+------------------+------------+------------+------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql('''  SELECT mfr, type,\n",
    "                                sum(calories) as sum_calories,\n",
    "                                min(calories) as min_calories,\n",
    "                                max(calories) as max_calories,\n",
    "                                avg(calories) as avg_calories,\n",
    "                   \n",
    "                                sum(carbo) as sum_carbo,\n",
    "                                min(carbo) as min_carbo,\n",
    "                                max(carbo) as max_carbo,\n",
    "                                avg(carbo) as avg_carbo,\n",
    "                   \n",
    "                                sum(vitamins) as sum_vitamins,\n",
    "                                min(vitamins) as min_vitamins,\n",
    "                                max(vitamins) as max_vitamins,\n",
    "                                avg(vitamins) as avg_vitamins,\n",
    "                   \n",
    "                                count(name) as count\n",
    "                        FROM cereal_sql\n",
    "                        GROUP BY mfr,type\n",
    "                        ORDER BY count DESC\n",
    "\n",
    "''')\n",
    "\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------------+------------+------------+------------+---------+---------+---------+---------+------------+------------+------------+------------+-----+\n",
      "|mfr|type|sum_calories|min_calories|max_calories|avg_calories|sum_carbo|min_carbo|max_carbo|avg_carbo|sum_vitamins|min_vitamins|max_vitamins|avg_vitamins|count|\n",
      "+---+----+------------+------------+------------+------------+---------+---------+---------+---------+------------+------------+------------+------------+-----+\n",
      "|  K|   C|        2500|          50|         160|      108.70|    348.0|      7.0|     22.0|    15.13|         800|          25|         100|       34.78|   23|\n",
      "|  G|   C|        2450|         100|         140|      111.36|    324.0|     10.5|     21.0|    14.73|         775|          25|         100|       35.23|   22|\n",
      "|  P|   C|         980|          90|         120|      108.89|    119.0|     11.0|     17.0|    13.22|         225|          25|          25|       25.00|    9|\n",
      "|  R|   C|         920|          90|         150|      115.00|    141.0|     14.0|     23.0|    17.63|         200|          25|          25|       25.00|    8|\n",
      "|  Q|   C|         660|          50|         120|       94.29|     81.0|      8.0|     14.0|    11.57|         100|           0|          25|       14.29|    7|\n",
      "|  N|   C|         420|          70|          90|       84.00|     75.0|      5.0|     20.0|    15.00|          50|           0|          25|       10.00|    5|\n",
      "|  A|   H|         100|         100|         100|      100.00|     16.0|     16.0|     16.0|    16.00|          25|          25|          25|       25.00|    1|\n",
      "|  Q|   H|         100|         100|         100|      100.00|     -1.0|     -1.0|     -1.0|    -1.00|           0|           0|           0|        0.00|    1|\n",
      "|  N|   H|         100|         100|         100|      100.00|     21.0|     21.0|     21.0|    21.00|           0|           0|           0|        0.00|    1|\n",
      "+---+----+------------+------------+------------+------------+---------+---------+---------+---------+------------+------------+------------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Formatação de valores decimais\n",
    "cereal = spark.sql('''  SELECT mfr, type,\n",
    "                                sum(calories) as sum_calories,\n",
    "                                min(calories) as min_calories,\n",
    "                                max(calories) as max_calories,\n",
    "                                cast(avg(calories) as decimal(10,2)) as avg_calories,\n",
    "                   \n",
    "                                sum(carbo) as sum_carbo,\n",
    "                                min(carbo) as min_carbo,\n",
    "                                max(carbo) as max_carbo,\n",
    "                                cast(avg(carbo) as decimal(10,2)) as avg_carbo,\n",
    "                   \n",
    "                                sum(vitamins) as sum_vitamins,\n",
    "                                min(vitamins) as min_vitamins,\n",
    "                                max(vitamins) as max_vitamins,\n",
    "                                cast(avg(vitamins) as decimal(10,2)) as avg_vitamins,\n",
    "                   \n",
    "                                count(name) as count\n",
    "                        FROM cereal_sql\n",
    "                        GROUP BY mfr,type\n",
    "                        ORDER BY count DESC\n",
    "\n",
    "''')\n",
    "\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case When Avançado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------+------------+------------+------------+------------+---------+---------+---------+---------+------------+------------+------------+------------+-----+\n",
      "|mfr|type|type_fruit|sum_calories|min_calories|max_calories|avg_calories|sum_carbo|min_carbo|max_carbo|avg_carbo|sum_vitamins|min_vitamins|max_vitamins|avg_vitamins|count|\n",
      "+---+----+----------+------------+------------+------------+------------+---------+---------+---------+---------+------------+------------+------------+------------+-----+\n",
      "|  K|   C|   Abacaxi|        2500|          50|         160|      108.70|    348.0|      7.0|     22.0|    15.13|         800|          25|         100|       34.78|   23|\n",
      "|  G|   C|    Goiaba|        2450|         100|         140|      111.36|    324.0|     10.5|     21.0|    14.73|         775|          25|         100|       35.23|   22|\n",
      "|  P|   C|      Pera|         980|          90|         120|      108.89|    119.0|     11.0|     17.0|    13.22|         225|          25|          25|       25.00|    9|\n",
      "|  R|   C|      Roma|         920|          90|         150|      115.00|    141.0|     14.0|     23.0|    17.63|         200|          25|          25|       25.00|    8|\n",
      "|  Q|   C| Espinafre|         660|          50|         120|       94.29|     81.0|      8.0|     14.0|    11.57|         100|           0|          25|       14.29|    7|\n",
      "|  N|   C| Nectarina|         420|          70|          90|       84.00|     75.0|      5.0|     20.0|    15.00|          50|           0|          25|       10.00|    5|\n",
      "|  A|   H|   Abacate|         100|         100|         100|      100.00|     16.0|     16.0|     16.0|    16.00|          25|          25|          25|       25.00|    1|\n",
      "|  Q|   H| Espinafre|         100|         100|         100|      100.00|     -1.0|     -1.0|     -1.0|    -1.00|           0|           0|           0|        0.00|    1|\n",
      "|  N|   H| Nectarina|         100|         100|         100|      100.00|     21.0|     21.0|     21.0|    21.00|           0|           0|           0|        0.00|    1|\n",
      "+---+----+----------+------------+------------+------------+------------+---------+---------+---------+---------+------------+------------+------------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Formatação de valores decimais\n",
    "cereal = spark.sql('''  SELECT mfr, type,\n",
    "                                (case\n",
    "                                    when mfr = \"K\" then \"Abacaxi\"\n",
    "                                    when mfr = \"G\" then \"Goiaba\"\n",
    "                                    when mfr = \"P\" then \"Pera\"\n",
    "                                    when mfr = \"R\" then \"Roma\"\n",
    "                                    when mfr = \"Q\" then \"Espinafre\"\n",
    "                                    when mfr = \"N\" then \"Nectarina\"\n",
    "                                    when mfr = \"A\" then \"Abacate\"\n",
    "                                    else \"NA\"\n",
    "                                end) as type_fruit,\n",
    "                                sum(calories) as sum_calories,\n",
    "                                min(calories) as min_calories,\n",
    "                                max(calories) as max_calories,\n",
    "                                cast(avg(calories) as decimal(10,2)) as avg_calories,\n",
    "                   \n",
    "                                sum(carbo) as sum_carbo,\n",
    "                                min(carbo) as min_carbo,\n",
    "                                max(carbo) as max_carbo,\n",
    "                                cast(avg(carbo) as decimal(10,2)) as avg_carbo,\n",
    "                   \n",
    "                                sum(vitamins) as sum_vitamins,\n",
    "                                min(vitamins) as min_vitamins,\n",
    "                                max(vitamins) as max_vitamins,\n",
    "                                cast(avg(vitamins) as decimal(10,2)) as avg_vitamins,\n",
    "                   \n",
    "                                count(name) as count\n",
    "                        FROM cereal_sql\n",
    "                        GROUP BY mfr,type\n",
    "                        ORDER BY count DESC\n",
    "\n",
    "''')\n",
    "\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InnerJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 2823\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES|      ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|        CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|         CITY|STATE|POSTALCODE|COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "|      10107|             30|     95.7|              2| 2871.0| 2/24/2003 0:00|Shipped|     1|       2|   2003|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|        NULL|          NYC|   NY|     10022|    USA|       NA|             Yu|            Kwai|   Small|\n",
      "|      10121|             34|    81.35|              5| 2765.9|  5/7/2003 0:00|Shipped|     2|       5|   2003|Motorcycles|  95|   S10_1678|  Reims Collectables|      26.47.1555|  59 rue de l'Abbaye|        NULL|        Reims| NULL|     51100| France|     EMEA|        Henriot|            Paul|   Small|\n",
      "|      10134|             41|    94.74|              2|3884.34|  7/1/2003 0:00|Shipped|     3|       7|   2003|Motorcycles|  95|   S10_1678|     Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|        NULL|        Paris| NULL|     75508| France|     EMEA|       Da Cunha|          Daniel|  Medium|\n",
      "|      10145|             45|    83.26|              6| 3746.7| 8/25/2003 0:00|Shipped|     3|       8|   2003|Motorcycles|  95|   S10_1678|   Toys4GrownUps.com|      6265557265|  78934 Hillside Dr.|        NULL|     Pasadena|   CA|     90003|    USA|       NA|          Young|           Julie|  Medium|\n",
      "|      10159|             49|    100.0|             14|5205.27|10/10/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Corporate Gift Id...|      6505551386|     7734 Strong St.|        NULL|San Francisco|   CA|      NULL|    USA|       NA|          Brown|           Julie|  Medium|\n",
      "|      10168|             36|    96.66|              1|3479.76|10/28/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Technics Stores Inc.|      6505556809|   9408 Furth Circle|        NULL|   Burlingame|   CA|     94217|    USA|       NA|         Hirano|            Juri|  Medium|\n",
      "|      10180|             29|    86.13|              9|2497.77|11/11/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|Daedalus Designs ...|      20.16.1555|184, chausse de T...|        NULL|        Lille| NULL|     59000| France|     EMEA|          Rance|         Martine|   Small|\n",
      "|      10188|             48|    100.0|              1|5512.32|11/18/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|        Herkku Gifts|   +47 2267 3215|Drammen 121, PR 7...|        NULL|       Bergen| NULL|    N 5804| Norway|     EMEA|         Oeztan|          Veysel|  Medium|\n",
      "|      10201|             22|    98.57|              2|2168.54| 12/1/2003 0:00|Shipped|     4|      12|   2003|Motorcycles|  95|   S10_1678|     Mini Wheels Co.|      6505555787|5557 North Pendal...|        NULL|San Francisco|   CA|      NULL|    USA|       NA|         Murphy|           Julie|   Small|\n",
      "|      10211|             41|    100.0|             14|4708.44| 1/15/2004 0:00|Shipped|     1|       1|   2004|Motorcycles|  95|   S10_1678|    Auto Canal Petit|  (1) 47.55.6555|   25, rue Lauriston|        NULL|        Paris| NULL|     75016| France|     EMEA|        Perrier|       Dominique|  Medium|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+-----+----------+-------+---------+---------------+----------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales = spark.read.csv('./sales_data_sample.csv', sep=',', inferSchema=True, header=True)\n",
    "\n",
    "print(f'Lines: {df_sales.count()}')\n",
    "df_sales.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ORDERNUMBER: integer (nullable = true)\n",
      " |-- QUANTITYORDERED: integer (nullable = true)\n",
      " |-- PRICEEACH: double (nullable = true)\n",
      " |-- ORDERLINENUMBER: integer (nullable = true)\n",
      " |-- SALES: double (nullable = true)\n",
      " |-- ORDERDATE: string (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- QTR_ID: integer (nullable = true)\n",
      " |-- MONTH_ID: integer (nullable = true)\n",
      " |-- YEAR_ID: integer (nullable = true)\n",
      " |-- PRODUCTLINE: string (nullable = true)\n",
      " |-- MSRP: integer (nullable = true)\n",
      " |-- PRODUCTCODE: string (nullable = true)\n",
      " |-- CUSTOMERNAME: string (nullable = true)\n",
      " |-- PHONE: string (nullable = true)\n",
      " |-- ADDRESSLINE1: string (nullable = true)\n",
      " |-- ADDRESSLINE2: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- POSTALCODE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- TERRITORY: string (nullable = true)\n",
      " |-- CONTACTLASTNAME: string (nullable = true)\n",
      " |-- CONTACTFIRSTNAME: string (nullable = true)\n",
      " |-- DEALSIZE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.createOrReplaceTempView('sales_sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES|      ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|        CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|         CITY|   STATE|POSTALCODE|  COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+\n",
      "|      10107|             30|     95.7|              2| 2871.0| 2/24/2003 0:00|Shipped|     1|       2|   2003|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|        NULL|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|   Small|\n",
      "|      10121|             34|    81.35|              5| 2765.9|  5/7/2003 0:00|Shipped|     2|       5|   2003|Motorcycles|  95|   S10_1678|  Reims Collectables|      26.47.1555|  59 rue de l'Abbaye|        NULL|        Reims|    NULL|     51100|   France|     EMEA|        Henriot|            Paul|   Small|\n",
      "|      10134|             41|    94.74|              2|3884.34|  7/1/2003 0:00|Shipped|     3|       7|   2003|Motorcycles|  95|   S10_1678|     Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|        NULL|        Paris|    NULL|     75508|   France|     EMEA|       Da Cunha|          Daniel|  Medium|\n",
      "|      10145|             45|    83.26|              6| 3746.7| 8/25/2003 0:00|Shipped|     3|       8|   2003|Motorcycles|  95|   S10_1678|   Toys4GrownUps.com|      6265557265|  78934 Hillside Dr.|        NULL|     Pasadena|      CA|     90003|      USA|       NA|          Young|           Julie|  Medium|\n",
      "|      10159|             49|    100.0|             14|5205.27|10/10/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Corporate Gift Id...|      6505551386|     7734 Strong St.|        NULL|San Francisco|      CA|      NULL|      USA|       NA|          Brown|           Julie|  Medium|\n",
      "|      10168|             36|    96.66|              1|3479.76|10/28/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Technics Stores Inc.|      6505556809|   9408 Furth Circle|        NULL|   Burlingame|      CA|     94217|      USA|       NA|         Hirano|            Juri|  Medium|\n",
      "|      10180|             29|    86.13|              9|2497.77|11/11/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|Daedalus Designs ...|      20.16.1555|184, chausse de T...|        NULL|        Lille|    NULL|     59000|   France|     EMEA|          Rance|         Martine|   Small|\n",
      "|      10188|             48|    100.0|              1|5512.32|11/18/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|        Herkku Gifts|   +47 2267 3215|Drammen 121, PR 7...|        NULL|       Bergen|    NULL|    N 5804|   Norway|     EMEA|         Oeztan|          Veysel|  Medium|\n",
      "|      10201|             22|    98.57|              2|2168.54| 12/1/2003 0:00|Shipped|     4|      12|   2003|Motorcycles|  95|   S10_1678|     Mini Wheels Co.|      6505555787|5557 North Pendal...|        NULL|San Francisco|      CA|      NULL|      USA|       NA|         Murphy|           Julie|   Small|\n",
      "|      10211|             41|    100.0|             14|4708.44| 1/15/2004 0:00|Shipped|     1|       1|   2004|Motorcycles|  95|   S10_1678|    Auto Canal Petit|  (1) 47.55.6555|   25, rue Lauriston|        NULL|        Paris|    NULL|     75016|   France|     EMEA|        Perrier|       Dominique|  Medium|\n",
      "|      10223|             37|    100.0|              1|3965.66| 2/20/2004 0:00|Shipped|     1|       2|   2004|Motorcycles|  95|   S10_1678|Australian Collec...|    03 9520 4555|   636 St Kilda Road|     Level 3|    Melbourne|Victoria|      3004|Australia|     APAC|       Ferguson|           Peter|  Medium|\n",
      "|      10237|             23|    100.0|              7|2333.12|  4/5/2004 0:00|Shipped|     2|       4|   2004|Motorcycles|  95|   S10_1678|     Vitachrome Inc.|      2125551500|   2678 Kingston Rd.|   Suite 101|          NYC|      NY|     10022|      USA|       NA|          Frick|         Michael|   Small|\n",
      "|      10251|             28|    100.0|              2|3188.64| 5/18/2004 0:00|Shipped|     2|       5|   2004|Motorcycles|  95|   S10_1678|Tekni Collectable...|      2015559350|       7476 Moss Rd.|        NULL|       Newark|      NJ|     94019|      USA|       NA|          Brown|         William|  Medium|\n",
      "|      10263|             34|    100.0|              2|3676.76| 6/28/2004 0:00|Shipped|     2|       6|   2004|Motorcycles|  95|   S10_1678|     Gift Depot Inc.|      2035552570| 25593 South Bay Ln.|        NULL|  Bridgewater|      CT|     97562|      USA|       NA|           King|           Julie|  Medium|\n",
      "|      10275|             45|    92.83|              1|4177.35| 7/23/2004 0:00|Shipped|     3|       7|   2004|Motorcycles|  95|   S10_1678|   La Rochelle Gifts|      40.67.8555|67, rue des Cinqu...|        NULL|       Nantes|    NULL|     44000|   France|     EMEA|        Labrune|          Janine|  Medium|\n",
      "|      10285|             36|    100.0|              6|4099.68| 8/27/2004 0:00|Shipped|     3|       8|   2004|Motorcycles|  95|   S10_1678|Marta's Replicas Co.|      6175558555| 39323 Spinnaker Dr.|        NULL|    Cambridge|      MA|     51247|      USA|       NA|      Hernandez|           Marta|  Medium|\n",
      "|      10299|             23|    100.0|              9|2597.39| 9/30/2004 0:00|Shipped|     3|       9|   2004|Motorcycles|  95|   S10_1678|Toys of Finland, Co.|     90-224 8555|       Keskuskatu 45|        NULL|     Helsinki|    NULL|     21240|  Finland|     EMEA|      Karttunen|           Matti|   Small|\n",
      "|      10309|             41|    100.0|              5|4394.38|10/15/2004 0:00|Shipped|     4|      10|   2004|Motorcycles|  95|   S10_1678|  Baane Mini Imports|      07-98 9555|Erling Skakkes ga...|        NULL|      Stavern|    NULL|      4110|   Norway|     EMEA|     Bergulfsen|           Jonas|  Medium|\n",
      "|      10318|             46|    94.74|              1|4358.04| 11/2/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|Diecast Classics ...|      2155551555|    7586 Pompton St.|        NULL|    Allentown|      PA|     70267|      USA|       NA|             Yu|           Kyung|  Medium|\n",
      "|      10329|             42|    100.0|              1|4396.14|11/15/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|        NULL|          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|  Medium|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabelas dimensionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+--------+-------+\n",
      "|     ORDERDATE|QTR_ID|MONTH_ID|YEAR_ID|\n",
      "+--------------+------+--------+-------+\n",
      "|1/10/2003 0:00|     1|       1|   2003|\n",
      "|1/10/2005 0:00|     1|       1|   2005|\n",
      "|1/12/2004 0:00|     1|       1|   2004|\n",
      "|1/12/2005 0:00|     1|       1|   2005|\n",
      "|1/15/2004 0:00|     1|       1|   2004|\n",
      "+--------------+------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tabela de datas\n",
    "calendar = spark.sql('''\n",
    "                  SELECT DISTINCT ORDERDATE, QTR_ID, MONTH_ID, YEAR_ID\n",
    "                  FROM sales_sql\n",
    "                  ORDER BY ORDERDATE\n",
    "\n",
    "''')\n",
    "calendar.createOrReplaceTempView('calendar')\n",
    "\n",
    "calendar.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------+-------+---------+-----------+---------------+\n",
      "|ORDERNUMBER|        CUSTOMERNAME|QUANTITYORDERED|  SALES|PRICEEACH|PRODUCTCODE|ORDERLINENUMBER|\n",
      "+-----------+--------------------+---------------+-------+---------+-----------+---------------+\n",
      "|      10100|Online Diecast Cr...|             22|1903.22|    86.51|   S18_4409|              4|\n",
      "|      10100|Online Diecast Cr...|             50| 3390.0|     67.8|   S18_2248|              2|\n",
      "|      10100|Online Diecast Cr...|             49|1689.03|    34.47|   S24_3969|              1|\n",
      "|      10100|Online Diecast Cr...|             30| 5151.0|    100.0|   S18_1749|              3|\n",
      "|      10101|Blauer See Auto, Co.|             26|3773.38|    100.0|   S18_2795|              1|\n",
      "+-----------+--------------------+---------------+-------+---------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tabela de vendas/pedidos\n",
    "orders = spark.sql('''\n",
    "                  SELECT DISTINCT ORDERNUMBER, CUSTOMERNAME, QUANTITYORDERED, SALES, PRICEEACH, PRODUCTCODE, ORDERLINENUMBER\n",
    "                  FROM sales_sql\n",
    "                  ORDER BY ORDERNUMBER\n",
    "\n",
    "''')\n",
    "\n",
    "orders.createOrReplaceTempView('orders')\n",
    "\n",
    "orders.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+------------+------------+-----+----------+---------+---------+\n",
      "|        CUSTOMERNAME|         PHONE|        ADDRESSLINE1|ADDRESSLINE2|        CITY|STATE|POSTALCODE|  COUNTRY|TERRITORY|\n",
      "+--------------------+--------------+--------------------+------------+------------+-----+----------+---------+---------+\n",
      "|      AV Stores, Co.|(171) 555-1555|   Fauntleroy Circus|        NULL|  Manchester| NULL|   EC2 5NT|       UK|     EMEA|\n",
      "|        Alpha Cognac|    61.77.6555|1 rue Alsace-Lorr...|        NULL|    Toulouse| NULL|     31000|   France|     EMEA|\n",
      "|  Amica Models & Co.|   011-4988555| Via Monte Bianco 34|        NULL|      Torino| NULL|     10100|    Italy|     EMEA|\n",
      "|Anna's Decoration...|  02 9936 8555|   201 Miller Street|    Level 15|North Sydney|  NSW|      2060|Australia|     APAC|\n",
      "|   Atelier graphique|    40.32.2555|      54, rue Royale|        NULL|      Nantes| NULL|     44000|   France|     EMEA|\n",
      "+--------------------+--------------+--------------------+------------+------------+-----+----------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tabela de clientes\n",
    "customer = spark.sql('''\n",
    "                  SELECT DISTINCT CUSTOMERNAME, PHONE, ADDRESSLINE1, ADDRESSLINE2, CITY, STATE, POSTALCODE, COUNTRY, TERRITORY\n",
    "                  FROM sales_sql\n",
    "                  ORDER BY CUSTOMERNAME\n",
    "\n",
    "''')\n",
    "\n",
    "customer.createOrReplaceTempView('customer')\n",
    "\n",
    "customer.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "2823\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "print(calendar.count())\n",
    "print(orders.count())\n",
    "print(customer.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823\n",
      "+-----------+--------------------+---------------+-------+---------+-----------+---------------+--------------------+----------------+--------------------+------------+------------+-----+----------+-------+---------+\n",
      "|ORDERNUMBER|        CUSTOMERNAME|QUANTITYORDERED|  SALES|PRICEEACH|PRODUCTCODE|ORDERLINENUMBER|        CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|        CITY|STATE|POSTALCODE|COUNTRY|TERRITORY|\n",
      "+-----------+--------------------+---------------+-------+---------+-----------+---------------+--------------------+----------------+--------------------+------------+------------+-----+----------+-------+---------+\n",
      "|      10308|       Mini Classics|             20| 4570.4|    100.0|   S10_4698|              1|       Mini Classics|      9145554562|3758 North Pendal...|        NULL|White Plains|   NY|     24067|    USA|       NA|\n",
      "|      10272|Diecast Classics ...|             35| 5818.4|    100.0|   S12_1108|              2|Diecast Classics ...|      2155551555|    7586 Pompton St.|        NULL|   Allentown|   PA|     70267|    USA|       NA|\n",
      "|      10219|Signal Collectibl...|             48|4891.68|    100.0|   S12_4473|              2|Signal Collectibl...|      4155554312|   2793 Furth Circle|        NULL|    Brisbane|   CA|     94217|    USA|       NA|\n",
      "|      10346|  Signal Gift Stores|             42|1516.62|    36.11|   S18_1342|              3|  Signal Gift Stores|      7025551838|     8489 Strong St.|        NULL|   Las Vegas|   NV|     83030|    USA|       NA|\n",
      "|      10356|     Lyon Souveniers|             27|1746.63|    64.69|   S18_1984|              2|     Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|        NULL|       Paris| NULL|     75508| France|     EMEA|\n",
      "+-----------+--------------------+---------------+-------+---------+-----------+---------------+--------------------+----------------+--------------------+------------+------------+-----+----------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master = spark.sql('''\n",
    "                SELECT *\n",
    "                FROM orders o\n",
    "                INNER JOIN customer c on o.CUSTOMERNAME = c.CUSTOMERNAME                 \n",
    "''')\n",
    "\n",
    "print(master.count())\n",
    "master.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "+-----------+----------+\n",
      "|ORDERNUMBER|      CITY|\n",
      "+-----------+----------+\n",
      "|      10300| Frankfurt|\n",
      "|      10385|San Rafael|\n",
      "|      10182|San Rafael|\n",
      "|      10140|Burlingame|\n",
      "|      10241|Strasbourg|\n",
      "+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master = spark.sql('''\n",
    "                SELECT DISTINCT o.ORDERNUMBER, C.CITY\n",
    "                FROM orders o\n",
    "                INNER JOIN customer c on o.CUSTOMERNAME = c.CUSTOMERNAME                 \n",
    "''')\n",
    "\n",
    "print(master.count())\n",
    "master.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
