{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Status|\n",
      "+------+\n",
      "|    OK|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql('''select \"OK\" as Status''')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 77\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|                name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|           100% Bran|  N|   C|      70|      4|  1|   130| 10.0|  5.0|     6|   280|      25|    3|   1.0|0.33|68.402973|\n",
      "|   100% Natural Bran|  Q|   C|     120|      3|  5|    15|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|\n",
      "|            All-Bran|  K|   C|      70|      4|  1|   260|  9.0|  7.0|     5|   320|      25|    3|   1.0|0.33|59.425505|\n",
      "|All-Bran with Ext...|  K|   C|      50|      4|  0|   140| 14.0|  8.0|     0|   330|      25|    3|   1.0| 0.5|93.704912|\n",
      "|      Almond Delight|  R|   C|     110|      2|  2|   200|  1.0| 14.0|     8|    -1|      25|    3|   1.0|0.75|34.384843|\n",
      "|Apple Cinnamon Ch...|  G|   C|     110|      2|  2|   180|  1.5| 10.5|    10|    70|      25|    1|   1.0|0.75|29.509541|\n",
      "|         Apple Jacks|  K|   C|     110|      2|  0|   125|  1.0| 11.0|    14|    30|      25|    2|   1.0| 1.0|33.174094|\n",
      "|             Basic 4|  G|   C|     130|      3|  2|   210|  2.0| 18.0|     8|   100|      25|    3|  1.33|0.75|37.038562|\n",
      "|           Bran Chex|  R|   C|      90|      2|  1|   200|  4.0| 15.0|     6|   125|      25|    1|   1.0|0.67|49.120253|\n",
      "|         Bran Flakes|  P|   C|      90|      3|  0|   210|  5.0| 13.0|     5|   190|      25|    3|   1.0|0.67|53.313813|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('./cereal.csv', sep=',', inferSchema=True, header=True)\n",
    "\n",
    "print(f'Lines: {df.count()}')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- mfr: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- calories: integer (nullable = true)\n",
      " |-- protein: integer (nullable = true)\n",
      " |-- fat: integer (nullable = true)\n",
      " |-- sodium: integer (nullable = true)\n",
      " |-- fiber: double (nullable = true)\n",
      " |-- carbo: double (nullable = true)\n",
      " |-- sugars: integer (nullable = true)\n",
      " |-- potass: integer (nullable = true)\n",
      " |-- vitamins: integer (nullable = true)\n",
      " |-- shelf: integer (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- cups: double (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate date with Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('cereal_sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|                name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|           100% Bran|  N|   C|      70|      4|  1|   130| 10.0|  5.0|     6|   280|      25|    3|   1.0|0.33|68.402973|\n",
      "|   100% Natural Bran|  Q|   C|     120|      3|  5|    15|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|\n",
      "|            All-Bran|  K|   C|      70|      4|  1|   260|  9.0|  7.0|     5|   320|      25|    3|   1.0|0.33|59.425505|\n",
      "|All-Bran with Ext...|  K|   C|      50|      4|  0|   140| 14.0|  8.0|     0|   330|      25|    3|   1.0| 0.5|93.704912|\n",
      "|      Almond Delight|  R|   C|     110|      2|  2|   200|  1.0| 14.0|     8|    -1|      25|    3|   1.0|0.75|34.384843|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cereal = spark.sql('''SELECT * FROM cereal_sql''')\n",
    "df_cereal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 74\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|                name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|           100% Bran|  N|   C|      70|      4|  1|   130| 10.0|  5.0|     6|   280|      25|    3|   1.0|0.33|68.402973|\n",
      "|   100% Natural Bran|  Q|   C|     120|      3|  5|    15|  2.0|  8.0|     8|   135|       0|    3|   1.0| 1.0|33.983679|\n",
      "|            All-Bran|  K|   C|      70|      4|  1|   260|  9.0|  7.0|     5|   320|      25|    3|   1.0|0.33|59.425505|\n",
      "|All-Bran with Ext...|  K|   C|      50|      4|  0|   140| 14.0|  8.0|     0|   330|      25|    3|   1.0| 0.5|93.704912|\n",
      "|      Almond Delight|  R|   C|     110|      2|  2|   200|  1.0| 14.0|     8|    -1|      25|    3|   1.0|0.75|34.384843|\n",
      "+--------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter = spark.sql('''SELECT * FROM cereal_sql WHERE type = \"C\"''')\n",
    "print(f'Lines: {filter.count()}')\n",
    "filter.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting lines as new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|total|\n",
      "+-----+\n",
      "|   23|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter = spark.sql('''SELECT COUNT(*) AS total FROM cereal_sql WHERE mfr = \"K\"''')\n",
    "filter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variações do comando Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+\n",
      "|                name|type|mfr|\n",
      "+--------------------+----+---+\n",
      "|           100% Bran|   C|  N|\n",
      "|   100% Natural Bran|   C|  Q|\n",
      "|            All-Bran|   C|  K|\n",
      "|All-Bran with Ext...|   C|  K|\n",
      "|      Almond Delight|   C|  R|\n",
      "+--------------------+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Colunas específicas\n",
    "cereal = spark.sql('''SELECT name,type,mfr FROM cereal_sql ''')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 77\n",
      "+----+---+\n",
      "|type|mfr|\n",
      "+----+---+\n",
      "|   C|  N|\n",
      "|   C|  Q|\n",
      "|   C|  K|\n",
      "|   C|  K|\n",
      "|   C|  R|\n",
      "+----+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Lines: 9\n",
      "+----+---+\n",
      "|type|mfr|\n",
      "+----+---+\n",
      "|   C|  P|\n",
      "|   C|  Q|\n",
      "|   C|  N|\n",
      "|   H|  Q|\n",
      "|   C|  R|\n",
      "+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valores distintos\n",
    "cereal = spark.sql('''SELECT type,mfr FROM cereal_sql ''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)\n",
    "\n",
    "cereal = spark.sql('''SELECT DISTINCT type,mfr FROM cereal_sql ''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comando Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 6\n",
      "+----+---+\n",
      "|type|mfr|\n",
      "+----+---+\n",
      "|   C|  P|\n",
      "|   C|  Q|\n",
      "|   C|  N|\n",
      "|   C|  R|\n",
      "|   C|  G|\n",
      "+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql('''SELECT DISTINCT type,mfr FROM cereal_sql WHERE type = \"C\"''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 19\n",
      "+------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|              name|mfr|type|calories|protein|fat|sodium|fiber|carbo|sugars|potass|vitamins|shelf|weight|cups|   rating|\n",
      "+------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "|       Apple Jacks|  K|   C|     110|      2|  0|   125|  1.0| 11.0|    14|    30|      25|    2|   1.0| 1.0|33.174094|\n",
      "|       Corn Flakes|  K|   C|     100|      2|  0|   290|  1.0| 21.0|     2|    35|      25|    1|   1.0| 1.0|45.863324|\n",
      "|         Corn Pops|  K|   C|     110|      1|  0|    90|  1.0| 13.0|    12|    20|      25|    2|   1.0| 1.0|35.782791|\n",
      "|Cracklin' Oat Bran|  K|   C|     110|      3|  3|   140|  4.0| 10.0|     7|   160|      25|    3|   1.0| 0.5|40.448772|\n",
      "|           Crispix|  K|   C|     110|      2|  0|   220|  1.0| 21.0|     3|    30|      25|    3|   1.0| 1.0|46.895644|\n",
      "+------------------+---+----+--------+-------+---+------+-----+-----+------+------+--------+-----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dupla condição\n",
    "cereal = spark.sql('''SELECT * FROM cereal_sql WHERE mfr = \"K\" AND calories >= 100''')\n",
    "print(f'Lines: {cereal.count()}')\n",
    "cereal.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "|mfr|type|count|\n",
      "+---+----+-----+\n",
      "|  A|   H|    1|\n",
      "|  P|   C|    9|\n",
      "|  K|   C|   23|\n",
      "|  G|   C|   22|\n",
      "|  Q|   C|    7|\n",
      "|  R|   C|    8|\n",
      "|  Q|   H|    1|\n",
      "|  N|   H|    1|\n",
      "|  N|   C|    5|\n",
      "+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento simples\n",
    "cereal = spark.sql(''' SELECT mfr,type,COUNT(*) AS count FROM cereal_sql GROUP BY mfr,type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+--------------+\n",
      "|mfr|type|count|total_calories|\n",
      "+---+----+-----+--------------+\n",
      "|  A|   H|    1|           100|\n",
      "|  P|   C|    9|           980|\n",
      "|  K|   C|   23|          2500|\n",
      "|  G|   C|   22|          2450|\n",
      "|  Q|   C|    7|           660|\n",
      "|  R|   C|    8|           920|\n",
      "|  Q|   H|    1|           100|\n",
      "|  N|   H|    1|           100|\n",
      "|  N|   C|    5|           420|\n",
      "+---+----+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento com mais de uma agregação\n",
    "cereal = spark.sql(''' SELECT mfr,type,COUNT(*) AS count, SUM(calories) as total_calories FROM cereal_sql GROUP BY mfr,type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+--------------+\n",
      "|mfr|type|count|total_calories|\n",
      "+---+----+-----+--------------+\n",
      "|  A|   H|    1|           100|\n",
      "|  P|   C|    9|           980|\n",
      "|  K|   C|   23|          2500|\n",
      "|  G|   C|   22|          2450|\n",
      "|  Q|   C|    7|           660|\n",
      "|  R|   C|    8|           920|\n",
      "|  Q|   H|    1|           100|\n",
      "|  N|   H|    1|           100|\n",
      "|  N|   C|    5|           420|\n",
      "+---+----+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamento com mais de uma agregação\n",
    "cereal = spark.sql(''' SELECT \\\n",
    "                           mfr, type, COUNT(*) AS count, SUM(calories) as total_calories \\\n",
    "                       FROM cereal_sql\\\n",
    "                       GROUP BY mfr,type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE WHEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|type|\n",
      "+----+\n",
      "|   C|\n",
      "|   H|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql(''' SELECT DISTINCT\\\n",
    "                           type \\\n",
    "                       FROM cereal_sql''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+-----+\n",
      "|mfr|type|category|count|\n",
      "+---+----+--------+-----+\n",
      "|  A|   H|  tipo H|    1|\n",
      "|  P|   C|  tipo C|    9|\n",
      "|  K|   C|  tipo C|   23|\n",
      "|  G|   C|  tipo C|   22|\n",
      "|  Q|   C|  tipo C|    7|\n",
      "|  R|   C|  tipo C|    8|\n",
      "|  Q|   H|  tipo H|    1|\n",
      "|  N|   H|  tipo H|    1|\n",
      "|  N|   C|  tipo C|    5|\n",
      "+---+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql(''' SELECT\\\n",
    "                           mfr, type, (case when type = \"C\" then \"tipo C\" else \"tipo H\" end) as category, count(*) as count \\\n",
    "                       FROM cereal_sql\\\n",
    "                       GROUP BY mfr, type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+-----+\n",
      "|mfr|type|category|count|\n",
      "+---+----+--------+-----+\n",
      "|  A|   H|    null|    1|\n",
      "|  P|   C|  tipo C|    9|\n",
      "|  K|   C|  tipo C|   23|\n",
      "|  G|   C|  tipo C|   22|\n",
      "|  Q|   C|  tipo C|    7|\n",
      "|  R|   C|  tipo C|    8|\n",
      "|  Q|   H|    null|    1|\n",
      "|  N|   H|    null|    1|\n",
      "|  N|   C|  tipo C|    5|\n",
      "+---+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Células comentadas em SQL\n",
    "cereal = spark.sql(''' SELECT\n",
    "                           mfr, type,\n",
    "                           (case\n",
    "                                when type = \"C\" then \"tipo C\"\n",
    "                                --when type = \"H\" then \"tipo B\"\n",
    "                                --else \"tipo H\"\n",
    "                           end) as category,\n",
    "                           count(*) as count \n",
    "                       FROM cereal_sql\n",
    "                       GROUP BY mfr, type''')\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultas avançadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------------+------------+------------+------------------+-----+\n",
      "|mfr|type|sum_calories|min_calories|max_calories|      avg_calories|count|\n",
      "+---+----+------------+------------+------------+------------------+-----+\n",
      "|  K|   C|        2500|          50|         160|108.69565217391305|   23|\n",
      "|  G|   C|        2450|         100|         140|111.36363636363636|   22|\n",
      "|  P|   C|         980|          90|         120|108.88888888888889|    9|\n",
      "|  R|   C|         920|          90|         150|             115.0|    8|\n",
      "|  Q|   C|         660|          50|         120| 94.28571428571429|    7|\n",
      "|  N|   C|         420|          70|          90|              84.0|    5|\n",
      "|  A|   H|         100|         100|         100|             100.0|    1|\n",
      "|  Q|   H|         100|         100|         100|             100.0|    1|\n",
      "|  N|   H|         100|         100|         100|             100.0|    1|\n",
      "+---+----+------------+------------+------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cereal = spark.sql('''  SELECT mfr, type,\n",
    "                                sum(calories) as sum_calories,\n",
    "                                min(calories) as min_calories,\n",
    "                                max(calories) as max_calories,\n",
    "                                avg(calories) as avg_calories,\n",
    "                                count(name) as count\n",
    "                        FROM cereal_sql\n",
    "                        GROUP BY mfr,type\n",
    "                        ORDER BY count DESC\n",
    "\n",
    "''')\n",
    "\n",
    "cereal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
